{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from kmeans import KMeans\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        num_clusters=3,\n",
    "        max_iter=100,\n",
    "        tol=1e-4,\n",
    "        seed: str = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize KMeans object.\n",
    "        Arguments:\n",
    "            dataset: numpy array of shape (n_samples, n_features)\n",
    "            k: number of clusters\n",
    "            max_iter: maximum number of iterations\n",
    "            tol: tolerance for convergence\n",
    "            seed: initial cluster centroids choice ['random','cluster']\n",
    "        \"\"\"\n",
    "        self.dataset = x_train\n",
    "        self.targets = y_train\n",
    "\n",
    "        self.k = num_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "        self.num_features = x_train.shape[1]\n",
    "        self.num_samples = x_train.shape[0]\n",
    "        self.losses = []\n",
    "\n",
    "        if seed == \"random\":\n",
    "            self.centroids = np.random.uniform(\n",
    "                size=(self.k, self.num_features))\n",
    "        elif seed == \"cluster\":\n",
    "            self.centroids = np.copy(self.dataset[np.random.choice(\n",
    "                self.num_samples, self.k, replace=False)])\n",
    "        else:\n",
    "            raise ValueError(\"Seed must be in ['random', 'cluster']\")\n",
    "            \n",
    "        self.old_centroids = np.copy(self.centroids)\n",
    "        self.cluster_labels = np.zeros(self.num_samples, dtype=int)\n",
    "        self.assign_clusters()\n",
    "\n",
    "    def converged(self):\n",
    "        if len(self.losses) < 2:\n",
    "            return False\n",
    "        if (abs(self.losses[-1] - self.losses[-2]) < self.tol):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def assign_clusters(self):\n",
    "        for i in range(self.num_samples):\n",
    "            self.cluster_labels[i] = np.argmin(\n",
    "                np.linalg.norm(self.dataset[i]-self.centroids, ord=2, axis=1))\n",
    "\n",
    "    def get_centroid_labels(self):\n",
    "        centroid_labels = np.zeros(self.k)\n",
    "        for i in range(self.k):\n",
    "            count = np.bincount(self.targets[self.cluster_labels == i])\n",
    "            if len(count) > 0:\n",
    "                centroid_labels[i] = np.argmax(count)\n",
    "        return centroid_labels\n",
    "\n",
    "    def fit(self):\n",
    "        for i in range(self.max_iter):\n",
    "            self.assign_clusters()\n",
    "            self.update_centroids()\n",
    "            loss = self.calc_loss()\n",
    "            self.losses.append(loss)\n",
    "#             print(f\"Iteration {i} Loss: {loss}\")\n",
    "#             print(\"---------------------------\")\n",
    "            if self.converged() is True:\n",
    "                print(f\"TOTAL ITERATIONS = {i}\")\n",
    "                break\n",
    "            self.old_centroids = np.copy(self.centroids)\n",
    "\n",
    "    def calc_loss(self):\n",
    "        loss = np.mean(np.linalg.norm(\n",
    "            self.dataset - self.centroids[self.cluster_labels], ord=2, axis=1), axis=0)\n",
    "        return loss\n",
    "\n",
    "    def calculate_loss(self):\n",
    "        loss = np.array(np.array([np.linalg.norm(self.data[i, :]-self.centers[int(\n",
    "            self.class_labels[i]), :], ord=2) for i in range(self.num_samples)]))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def update_centroids(self):\n",
    "        for i in range(self.k):\n",
    "            alloted = self.dataset[self.cluster_labels == i]\n",
    "            if len(alloted) > 0:\n",
    "                self.centroids[i] = np.mean(alloted, axis=0)\n",
    "            else:\n",
    "                self.centroids[i] = np.zeros(self.num_features)\n",
    "\n",
    "    def predict(self, x):\n",
    "        labels = np.zeros(x.shape[0], dtype=int)\n",
    "        for i in range(x.shape[0]):\n",
    "            labels[i] = np.argmin(\n",
    "                np.linalg.norm(x[i]-self.centroids, ord=2, axis=1))\n",
    "        return self.get_centroid_labels()[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # normalize training and test data\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "    digits = []\n",
    "    targets = []\n",
    "    for i in range(10):\n",
    "        images = x_train[y_train == i]\n",
    "        digits.append(images[np.random.choice(\n",
    "            len(images), 100, replace=False)])\n",
    "        targets.append(np.full((100,), i))\n",
    "\n",
    "    x_train = np.vstack(digits)\n",
    "    y_train = np.hstack(targets)\n",
    "\n",
    "    # shuffle the data\n",
    "    permutation = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[permutation]\n",
    "    y_train = y_train[permutation]\n",
    "\n",
    "    test_indices = np.random.choice(x_test.shape[0], 50)\n",
    "    x_test = x_test[test_indices]\n",
    "    y_test = y_test[test_indices]\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def plot_centroids(kmeans, centroids):\n",
    "    centroid_images = np.copy(centroids.reshape(kmeans.k, 28, 28))\n",
    "    centroid_images = centroid_images * 255\n",
    "\n",
    "    centroid_labels = kmeans.get_centroid_labels()\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    nrows = 4\n",
    "    ncols = kmeans.k // nrows + kmeans.k % nrows\n",
    "    for i in range(kmeans.k):\n",
    "        fig.add_subplot(nrows, ncols, i+1)\n",
    "        plt.imshow(centroid_images[i], cmap=\"gray\")\n",
    "        plt.title(f\"Label: {centroid_labels[i]}\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def classify_images(num_clusters=20, max_iter=200, tol=1e-6, seed=\"cluster\"):\n",
    "    # load the mnist data\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    # create a kmeans instance\n",
    "    kmeans = KMeans(x_train, y_train,\n",
    "                    num_clusters=num_clusters,\n",
    "                    max_iter=max_iter,\n",
    "                    tol=tol,\n",
    "                    seed=seed)\n",
    "\n",
    "    kmeans.fit()  # train the model\n",
    "    # predict the labels from input labels and centroids\n",
    "    predictions = kmeans.predict(x_test)\n",
    "    print(f\"Accuracy: {np.mean(predictions == y_test)}\")  # print the accuracy\n",
    "    plot_centroids(kmeans, kmeans.centroids)  # plot the centroids\n",
    "\n",
    "\n",
    "def plot_jclust(max_iter=200, tol=1e-6, seed=\"cluster\"):\n",
    "    k = np.arange(start=5, stop=21, step=1, dtype=int)\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    # create a kmeans instance\n",
    "    jclust = []\n",
    "    accuracy = []\n",
    "    for num_clusters in k:\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"K = {num_clusters}\")\n",
    "        kmeans = KMeans(x_train, y_train,\n",
    "                        num_clusters=num_clusters,\n",
    "                        max_iter=max_iter,\n",
    "                        tol=tol,\n",
    "                        seed=seed)\n",
    "        kmeans.fit()\n",
    "        loss = kmeans.calc_loss()\n",
    "        print(f\"TOTAL LOSS = {loss}\")\n",
    "        jclust.append(loss)\n",
    "        predictions = kmeans.predict(x_test)\n",
    "        acc = np.mean(predictions == y_test)\n",
    "        print(f\"Accuracy = {acc}\\n\")\n",
    "        accuracy.append(acc)\n",
    "        \n",
    "    plt.plot(k, jclust)\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"J-Clustering Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(k, accuracy)\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Accuracy on test set\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
