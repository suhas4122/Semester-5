{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import wikipedia\n",
    "import random\n",
    "\n",
    "CONVERGENCE_DELTA = 1e-5\n",
    "MAXIMUM_ITERATIONS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_articles = [\n",
    "    'Linear algebra',\n",
    "    'Data Science',\n",
    "    'Artificial intelligence',\n",
    "    'European Central Bank',\n",
    "    'Financial technology',\n",
    "    'International Monetary Fund',\n",
    "    'Basketball',\n",
    "    'Swimming',\n",
    "    'Cricket'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        num_clusters=3,\n",
    "        seed: str = \"random\",\n",
    "    ):\n",
    "        self.dataset = x_train\n",
    "        self.targets = y_train\n",
    "        self.k = num_clusters\n",
    "        self.num_features = x_train.shape[1]\n",
    "        self.num_samples = x_train.shape[0]\n",
    "        if seed == \"random\":\n",
    "            self.centroids = self.random_initialise_centroids()\n",
    "        elif seed == \"custom\":\n",
    "            self.centroids = self.initialise_from_data()\n",
    "        else:\n",
    "            raise ValueError(\"Cohoose a seed between ['random', 'custom']\") \n",
    "        self.old_centroids = np.copy(self.centroids)\n",
    "        self.cluster_labels = np.zeros(self.num_samples, dtype=int)\n",
    "        for i in range(self.num_samples):\n",
    "            self.cluster_labels[i] = np.argmin(\n",
    "                np.linalg.norm(self.dataset[i]-self.centroids, ord=2, axis=1))\n",
    "\n",
    "        \n",
    "    def random_initialise_centroids(self):\n",
    "        mean = np.mean(self.dataset, axis = 0)\n",
    "        std = np.std(self.dataset, axis = 0)\n",
    "        return np.random.randn(self.k, self.num_features)*std + mean\n",
    "    \n",
    "    def initialise_from_data(self):\n",
    "        centroids = np.copy(self.dataset[np.random.choice(\n",
    "                self.num_samples, self.k, replace=(False if self.k <= self.num_samples else True))])\n",
    "        return centroids \n",
    "        \n",
    "    def get_centroid_labels(self):\n",
    "        centroid_labels = np.zeros(self.k)\n",
    "        for i in range(self.k):\n",
    "            count = np.bincount(self.targets[self.cluster_labels == i])\n",
    "            if len(count) > 0:\n",
    "                centroid_labels[i] = np.argmax(count)\n",
    "        return centroid_labels\n",
    "    \n",
    "    def calculate_loss(self):\n",
    "        loss = np.mean(np.linalg.norm(\n",
    "            self.dataset - self.centroids[self.cluster_labels], ord=2, axis=1), axis=0)\n",
    "        return loss\n",
    "    \n",
    "    def fit(self):\n",
    "        for i in range(MAXIMUM_ITERATIONS):\n",
    "            # assigning clusters to all data points \n",
    "            for i in range(self.num_samples):\n",
    "                self.cluster_labels[i] = np.argmin(\n",
    "                    np.linalg.norm(self.dataset[i]-self.centroids, ord=2, axis=1))\n",
    "            prev_centers = np.copy(self.centroids)\n",
    "            converged = True\n",
    "            for i in range(self.k):\n",
    "                alloted = self.dataset[self.cluster_labels == i]\n",
    "                if len(alloted) > 0:\n",
    "                    self.centroids[i] = np.mean(alloted, axis=0)\n",
    "                else:\n",
    "                    self.centroids[i] = np.zeros(self.num_features)\n",
    "                if np.linalg.norm(prev_centers[i] - self.centroids[i]) > CONVERGENCE_DELTA:\n",
    "                    converged = False\n",
    "            loss = self.calculate_loss()\n",
    "            if converged is True:\n",
    "                print(f\"TOTAL ITERATIONS = {i}\")\n",
    "                break\n",
    "            self.old_centroids = np.copy(self.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for article_name in given_articles:\n",
    "    text = wikipedia.page(article_name, preload=True).content\n",
    "    articles.append(text)\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "x_train = vectorizer.fit_transform(articles).toarray()\n",
    "y_train = np.arange(len(given_articles))\n",
    "k = [4, 8, 12]\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(60)\n",
    "np.random.seed(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 4\n",
      "TOTAL ITERATIONS = 3\n",
      "Cluster no. 1: ['Data Science']\n",
      "Cluster no. 2: ['Basketball', 'Swimming', 'Cricket']\n",
      "Cluster no. 3: ['European Central Bank', 'Financial technology', 'International Monetary Fund']\n",
      "Cluster no. 4: ['Linear algebra', 'Artificial intelligence']\n",
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 8\n",
      "TOTAL ITERATIONS = 7\n",
      "Cluster no. 1: ['Financial technology']\n",
      "Cluster no. 2: ['Artificial intelligence']\n",
      "Cluster no. 3: ['Data Science']\n",
      "Cluster no. 4: ['International Monetary Fund']\n",
      "Cluster no. 5: ['Swimming']\n",
      "Cluster no. 6: ['Linear algebra']\n",
      "Cluster no. 7: ['European Central Bank']\n",
      "Cluster no. 8: ['Basketball', 'Cricket']\n",
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 12\n",
      "TOTAL ITERATIONS = 11\n",
      "Cluster no. 1: ['Financial technology']\n",
      "Cluster no. 2: ['Basketball', 'Cricket']\n",
      "Cluster no. 3: ['Data Science']\n",
      "Cluster no. 4: ['European Central Bank']\n",
      "Cluster no. 5: []\n",
      "Cluster no. 6: ['Swimming']\n",
      "Cluster no. 7: ['Linear algebra']\n",
      "Cluster no. 8: []\n",
      "Cluster no. 9: ['Artificial intelligence']\n",
      "Cluster no. 10: []\n",
      "Cluster no. 11: ['International Monetary Fund']\n",
      "Cluster no. 12: []\n"
     ]
    }
   ],
   "source": [
    "for num_clusters in k:\n",
    "    kmeans = KMeans(x_train, y_train, num_clusters=num_clusters, seed='custom')\n",
    "    print(f\"\\n----------------------------------\\nNUMBER OF CLUSTERS = {num_clusters}\")\n",
    "    kmeans.fit()\n",
    "    losses.append(kmeans.calculate_loss())\n",
    "    clusters = [[] for i in range(num_clusters)]\n",
    "    for i, article in enumerate(given_articles):\n",
    "        index = kmeans.cluster_labels[i]\n",
    "        clusters[index].append(article)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(\"Cluster no. {}: {}\".format(i+1, cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the part where clusters are initialised randomly, as we can observe many clusters remain empty and classification is not as good as when clusters are initialised from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 4\n",
      "TOTAL ITERATIONS = 3\n",
      "Cluster no. 1: []\n",
      "Cluster no. 2: ['Linear algebra', 'Cricket']\n",
      "Cluster no. 3: ['Data Science']\n",
      "Cluster no. 4: ['Artificial intelligence', 'European Central Bank', 'Financial technology', 'International Monetary Fund', 'Basketball', 'Swimming']\n",
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 8\n",
      "TOTAL ITERATIONS = 7\n",
      "Cluster no. 1: ['European Central Bank']\n",
      "Cluster no. 2: []\n",
      "Cluster no. 3: ['International Monetary Fund']\n",
      "Cluster no. 4: ['Artificial intelligence', 'Cricket']\n",
      "Cluster no. 5: []\n",
      "Cluster no. 6: ['Financial technology', 'Basketball']\n",
      "Cluster no. 7: ['Swimming']\n",
      "Cluster no. 8: ['Linear algebra', 'Data Science']\n",
      "\n",
      "----------------------------------\n",
      "NUMBER OF CLUSTERS = 12\n",
      "TOTAL ITERATIONS = 11\n",
      "Cluster no. 1: ['Linear algebra', 'Data Science']\n",
      "Cluster no. 2: []\n",
      "Cluster no. 3: []\n",
      "Cluster no. 4: ['European Central Bank']\n",
      "Cluster no. 5: ['Artificial intelligence', 'Financial technology']\n",
      "Cluster no. 6: ['Basketball']\n",
      "Cluster no. 7: []\n",
      "Cluster no. 8: []\n",
      "Cluster no. 9: []\n",
      "Cluster no. 10: ['International Monetary Fund']\n",
      "Cluster no. 11: ['Swimming', 'Cricket']\n",
      "Cluster no. 12: []\n"
     ]
    }
   ],
   "source": [
    "for num_clusters in k:\n",
    "    kmeans = KMeans(x_train, y_train, num_clusters=num_clusters, seed='random')\n",
    "    print(f\"\\n----------------------------------\\nNUMBER OF CLUSTERS = {num_clusters}\")\n",
    "    kmeans.fit()\n",
    "    losses.append(kmeans.calculate_loss())\n",
    "    clusters = [[] for i in range(num_clusters)]\n",
    "    for i, article in enumerate(given_articles):\n",
    "        index = kmeans.cluster_labels[i]\n",
    "        clusters[index].append(article)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(\"Cluster no. {}: {}\".format(i+1, cluster))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
